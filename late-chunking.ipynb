{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff023ad9-5d9b-4bdb-b561-dd8544cf277d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "from itertools import accumulate\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "from typing import NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42628c6d-4d20-489a-b81c-af5ea536c38f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEVICE = \"mps\"\n",
    "BATCH_SIZE = 2\n",
    "MODEL_ID = \"jinaai/jina-embeddings-v2-base-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970311ad-b72a-4d46-8b34-764c9af9836f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batched(xs: list, batch_size: int) -> list[list]:\n",
    "    return [\n",
    "        xs[i:i + batch_size]\n",
    "        for i in range(0, len(xs), batch_size)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc710a92-408c-4457-b7c5-e31ffb7b8b7c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_source_doc_lines() -> list[str]:\n",
    "    contents: str\n",
    "    with open(\"./zoom_earnings_call_2024_q3.txt\", \"r\") as f:\n",
    "        contents = f.read()\n",
    "        pass\n",
    "    return [\n",
    "        line.strip()\n",
    "        for line in contents.split(\"\\n\")\n",
    "        if line.strip()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06df2d43-db3f-42dc-bdf9-7ebd87a79d92",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    return AutoModel.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        trust_remote_code=True,\n",
    "        device_map=DEVICE,\n",
    "    )\n",
    "\n",
    "def load_tokenizer():\n",
    "    return AutoTokenizer.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        trust_remote_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3b0e75-a6ff-459d-97b5-4865452a2a00",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4db797-4017-411f-aa83-89c4c60770f9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf64c38-07c8-407e-b85e-63a1a96d3da8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WINDOW_LINES = 10\n",
    "WINDOW_OVERLAP = 1\n",
    "WINDOW_STEP_SIZE = WINDOW_LINES - WINDOW_OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f39587-063c-421f-b069-0854a2172a67",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = get_source_doc_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c44804b-f2a5-4dd7-9309-394b20dae7a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0bca9eb-f912-4b21-a007-2da323ad90e5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_pool(\n",
    "        *,\n",
    "        all_embeddings: torch.Tensor, # 2-d\n",
    "        line_lengths: list[int],\n",
    ") -> list[torch.Tensor]:\n",
    "    assert len(all_embeddings.shape) == 2, \"Expected a 2-d tensor\"\n",
    "    assert all_embeddings.shape[0] - 2 == sum(line_lengths), f\"Expected {all_embeddings.shape[0]} lines, got {sum(line_lengths)}\"\n",
    "    line_offsets = [0, *accumulate(line_lengths)]\n",
    "    meaningful_embeddings = all_embeddings[1:-1]\n",
    "    pool_groups = [\n",
    "        meaningful_embeddings[lo:hi]\n",
    "        for lo, hi in zip(line_offsets, line_offsets[1:])\n",
    "    ]\n",
    "    pool_groups[0] = torch.cat((pool_groups[0], all_embeddings[:1]))\n",
    "    pool_groups[-1] = torch.cat((pool_groups[-1], all_embeddings[-1:]))\n",
    "    return [\n",
    "        group.mean(dim=0)\n",
    "        for group in pool_groups\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e998e48c-4967-4ff6-83dd-0126c43ce6b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_groups = [\n",
    "    lines[i:i+WINDOW_LINES]\n",
    "    for i in range(0, len(lines), WINDOW_STEP_SIZE)\n",
    "]\n",
    "len(line_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7e3282f-458e-41a1-9f2c-0ad826835284",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pooled_line_embeddings: list[torch.tensor] = []\n",
    "\n",
    "for i, line_group in enumerate(line_groups):\n",
    "    # print(i)\n",
    "    with torch.no_grad():\n",
    "        complete_chunk_tokenized = tokenizer(\n",
    "            \"\\n\".join(line_group),\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        line_lengths = [\n",
    "            len(tokenizer(line)[\"input_ids\"]) - 2 # account for '[CLS]' and '[SEP]'\n",
    "            for line in line_group\n",
    "        ]\n",
    "        all_token_embeddings = model(\n",
    "            **complete_chunk_tokenized\n",
    "        )[\"last_hidden_state\"].squeeze() # no batch dimension\n",
    "        line_group_line_embeddings = mean_pool(\n",
    "            all_embeddings=all_token_embeddings,\n",
    "            line_lengths=line_lengths,\n",
    "        )\n",
    "        if i == 0:\n",
    "            # we get all of the first group\n",
    "            pooled_line_embeddings.extend(line_group_line_embeddings)\n",
    "            continue\n",
    "        # otherwise, take only the new lines from this group\n",
    "        pooled_line_embeddings.extend(line_group_line_embeddings[WINDOW_OVERLAP:])\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe1fd2-ff5c-412a-a41a-1e895e419554",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Unpooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa23c7c9-f7fd-4d29-a2ad-ba32004dd666",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unpooled_line_embeddings: list[torch.Tensor] = []\n",
    "for i, line in enumerate(lines):\n",
    "    # print(i)\n",
    "    with torch.no_grad():\n",
    "        tokenized_line = tokenizer(\n",
    "            line,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(DEVICE)\n",
    "        line_embedding = model(\n",
    "            **tokenized_line\n",
    "        )[\"pooler_output\"].squeeze()\n",
    "        unpooled_line_embeddings.append(line_embedding)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe53fa5f-3dba-4de0-a9bd-cde45905aa37",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EmbeddedLine(NamedTuple):\n",
    "    line_number: int\n",
    "    contents: str\n",
    "    embedding: list[float]\n",
    "    pass\n",
    "\n",
    "\n",
    "class EmbeddingSearcher:\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedded_lines: list[torch.Tensor],\n",
    "    ):\n",
    "        self.line_embeddings = [\n",
    "            np.array(e.to(\"cpu\"))\n",
    "            for e in embedded_lines\n",
    "        ]\n",
    "        self.lines = {\n",
    "            i: EmbeddedLine(\n",
    "                line_number=i,\n",
    "                embedding=e,\n",
    "                contents=lines[i],\n",
    "            )\n",
    "            for i, e in enumerate(embedded_lines)\n",
    "        }\n",
    "        return\n",
    "\n",
    "    def _find_nearest_line_indexes(self, query: str, k: int) -> list[int]:\n",
    "        # could do this once per query...\n",
    "        query_embed = model.encode([query])\n",
    "        similarities = cosine_similarity(\n",
    "            query_embed,\n",
    "            self.line_embeddings,\n",
    "        ).squeeze()\n",
    "        top = similarities.argsort()[-k:]\n",
    "        return list(reversed(top.tolist()))\n",
    "\n",
    "    def search(self, query: str, k: int = 4) -> list[EmbeddedLine]:\n",
    "        indexes = self._find_nearest_line_indexes(query, k=k)\n",
    "        return [\n",
    "            self.lines[i]\n",
    "            for i in indexes\n",
    "        ]\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8fb56da-f7c5-4243-911b-026594bf2db6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/gwj34jjx21lcg89_06hppbbm0000gn/T/ipykernel_53729/3887545951.py:14: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  np.array(e.to(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "pooled_searcher = EmbeddingSearcher(pooled_line_embeddings)\n",
    "unpooled_searcher = EmbeddingSearcher(unpooled_line_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dac2c959-6e23-442e-a25a-1fb4cceb4657",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_search_results(query: str):\n",
    "    default_results = unpooled_searcher.search(query, k=3)\n",
    "    pooled_results = pooled_searcher.search(query, k=3)\n",
    "    print(\"UNPOOLED RESULTS:\")\n",
    "    for result in default_results:\n",
    "        print(\"line #\", result.line_number)\n",
    "        print(result.contents)\n",
    "        pass\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"POOLED RESULTS:\")\n",
    "    for result in pooled_results:\n",
    "        print(\"line #\", result.line_number)\n",
    "        print(result.contents)\n",
    "        pass\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4846e5b2-c591-4864-a97b-ac58f9a033b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c217dda4fa4780a1caf726bbb6f472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a28a21c037f49c5828b9cc6e7e4213f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNPOOLED RESULTS:\n",
      "line # 256\n",
      "So, I'm just curious how many customers are showing that interest? What kind of scenarios they can design and, therefore, maybe how to think through the monetization potential at that price point?\n",
      "line # 57\n",
      "And our first question will come from Meta Marshall with Morgan Stanley.\n",
      "line # 113\n",
      "But as Eric and I began our conversations over the interview process, I got more and more excited about where I saw Zoom going to an AI-first platform company and could see a lot of the seeds, if you will, of growth being planted and starting to come to fruition. So, got very excited about that. And maybe, you know, my learning sense has been delightful, honestly, to see the customer love and the pace of innovation. I think you'd heard about it before, but to be among it, I think, has been a delight.\n",
      "\n",
      "\n",
      "POOLED RESULTS:\n",
      "line # 18\n",
      "Kelcey McKinley -- Event Consultant\n",
      "line # 16\n",
      "Mark Murphy -- Analyst\n",
      "line # 11\n",
      "Siti Panigrahi -- Analyst\n"
     ]
    }
   ],
   "source": [
    "compare_search_results(\"Who were the attendees on the call?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aafcc51f-1e24-48f4-b08d-045d75466374",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9360755d0d64f7386dc6fdd075a4c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b903a61ccbf4df4a3b73a8739dfd2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNPOOLED RESULTS:\n",
      "line # 50\n",
      "Operating cash flow and free cash flow margins in the quarter were 41% and 38.9%, respectively. We ended the quarter with approximately $7.7 billion in cash, cash equivalents, and marketable securities, excluding restricted cash. Under the pre-existing $1.5 billion share buy-back plan, in Q3, we purchased 4.4 million shares for $302 million, increasing our repurchases quarter over quarter by $14 million. And at the end of Q3, we repurchased 11.6 million shares for $739 million.\n",
      "line # 221\n",
      "OK.\n",
      "line # 142\n",
      "OK.\n",
      "\n",
      "\n",
      "POOLED RESULTS:\n",
      "line # 207\n",
      "We want to build a long-term trust. Given some time, the customer realized Zoom not only very stable ease of use, and also, we introduced more and more services, they would like to consolidate it into the Zoom platform. From that perspective, I think more opportunities for us to monetize as a platform player and in order to mention AI as well. So, that's our strategy.\n",
      "line # 201\n",
      "So, you really create an iconic brand with Zoom Video, you know, on that point solution space and have now expanded into other areas, the new names Zoom Communications not captures at all. You know, you have Phone now, you have Contact Center, adding AI on top, arguably even edging into work management with some of the products that you're rolling out. So, you know, the delineation is less clear now between yourself and competitors in other areas. So, how do you think about attacking the market? Is it purely based on product? Or how important is price as you try to win new business?\n",
      "line # 61\n",
      "Yeah, so Meta, this is a great question. That's the theme of Zoomtopia this year is really about AI. You know, we launched the AI Companion 1.0 last year. And with more and more customers, they enable AI, and also at Zoomtopia, we mentioned there are over 4 million accounts who are already enabled AI Companion.\n"
     ]
    }
   ],
   "source": [
    "compare_search_results(\"What are the major challenges facing Zoom?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4f2f100-16c7-465d-9289-9a4078e3026a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48867ff92c664a4fb1d34a9b645e9c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e1d3b56b084e5bbd50b508d02a83d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNPOOLED RESULTS:\n",
      "line # 256\n",
      "So, I'm just curious how many customers are showing that interest? What kind of scenarios they can design and, therefore, maybe how to think through the monetization potential at that price point?\n",
      "line # 217\n",
      "I know Meta announced that it would be sunsetting the Meta Workplace product, and it would be in stages over '25 and '26 in the -- to you customers toward Workvivo. Can you guys help us think about how you're thinking about that ramp? You've had good momentum there. Customers grew 72% year over year. Can you quantify maybe how much of the growth is coming from Meta and how we should think about that momentum going forward?\n",
      "line # 74\n",
      "I'm curious, where are the budgets for AI coming from? Is it from a separate pool from your customers? Or are they taking the budgets out of budgets -- or AI money out of budgets that were designed for Zoom? And also, a follow-up question on the macro, a tone of customer conversations post the elections, do you sense that there's slightly higher animal spirits, better appetite to spend in tech -- on tech and on Zoom's products in particular? Thank you so much.\n",
      "\n",
      "\n",
      "POOLED RESULTS:\n",
      "line # 230\n",
      "And they build up a lot of the natural things that Zoom has strengthen certain industries like retail, as well as frontline. So, I think, yes, the Meta partnership is part of that, and there are some durable dynamics to underscore a lot of the things that Eric talked about.\n",
      "line # 229\n",
      "Maybe just to add in from my standpoint, yes, the Meta partnership is driving the growth. We're not going to quantify it or speak to it. But I think if you look at a lot of the underlying metrics that we said in our prepared remarks, they tell a more holistic story for Workvivo growth and a lot of the things that we've been focused on, you know, from geo-expansion to partner dynamics to. you know, getting those large customers, as well as breadth.\n",
      "line # 227\n",
      "And also, we also want to innovate more on Workvivo. Doubling on that, I think, gives us more opportunity, and it will further grow that business. You know, I think if you at the growth rate and quarter over quarter, year over year, it's pretty, you know, exciting. And I think that business can contribute more to our business down the road.\n"
     ]
    }
   ],
   "source": [
    "compare_search_results(\"What are the major opportunities for growth available to Zoom?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "name": "late-chunking-final.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
